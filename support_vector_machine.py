# -*- coding: utf-8 -*-
"""Support_Vector_Machine.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155ULDQkVC1o1htEEL82ysd_00B5yKiNc
"""

import pandas as pd
import numpy as np
from sklearn import svm
import matplotlib.pyplot as plt

#Import scikit-learn dataset library
from sklearn import datasets

#Load dataset
cancer = datasets.load_breast_cancer()

# print the names of the 13 features
print("Features: ", cancer.feature_names)

# print the label type of cancer('malignant' 'benign')
print("Labels: ", cancer.target_names)

# print data(feature)shape
cancer.data.shape

# print the cancer data features (top 5 records)
print(cancer.data[0:5])

# print the cancer labels (0:malignant, 1:benign)
print(cancer.target)

# Import train_test_split function
from sklearn.model_selection import train_test_split

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

# Add missing features to X_test
missing_features = clf.n_features_in_ - X_test.shape[1]
X_test = np.pad(X_test, (0, missing_features), 'constant')


y_pred = clf.predict(X_test)
print(y_pred)

print(clf.n_features_in_)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
svm_accuracy= metrics.accuracy_score(y_test, y_pred)

print("Accuracy is:",svm_accuracy)

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

import matplotlib.pyplot as plt

X = cancer.data;
Y = cancer.target;

# Get the hyperplane
w = clf.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(0, 6)
yy = a * xx - (clf.intercept_[0]) / w[1]

# Plot the data points and the hyperplane
plt.figure(figsize=(6, 5))
plt.scatter(X[:, 0], X[:, 1], c=Y, cmap='viridis')
plt.plot(xx, yy, 'k-', label='Hyperplane')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.title('SVM Classification')
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_test)
nb_accuracy = accuracy_score(y_test, y_pred_gnb)
print("nb_accuracy",nb_accuracy)

models = ["Naive Bayes", "SVM"]
accuracies = [nb_accuracy, svm_accuracy]

import matplotlib.pyplot as plt

plt.bar(models, accuracies, width=0.4)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Naive Bayes vs. SVM Accuracy Comparison")
plt.show()